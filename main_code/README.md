## 边缘服务器

### Cluster类
server_pool : 服务器资源池  
dists : 服务器间距离  
edge_num : 边缘服务器数量  
arrival_rate : 工作流到达率  


### Server类
#### 成员变量
server_id : 服务器编号  
cpu_capacity : 当前可用cpu  
mem_capacity : 当前可用内存  
func_types : 存储的函数镜像  
waiting_queue : 等待运行队列  
workflow_queue : 接收到的工作流队列  
arrival_rate : 该服务器接收工作流的速率  
interarrival_time : 工作流到达间隔时间  

#### 成员函数
reset_time() : 重置工作流到达间隔时间  
receive_workflow(workflow_id, server_id, arrival_time) : 服务器接收工作流  
- 将工作流添加到服务器的**工作流队列**中  
- 将工作流按照拓扑排序拆成任务，再将每个任务的函数放入到服务器的等待队列中  


## 资源
### Workflow类
wf_id : 工作流编号  
wf_type : 工作流类型  
arrival_time : 工作里到达时间  
arrival_server : 工作流到达的服务器编号  
deadline : 工作流截止期  
tasks : 工作流包含的所有任务(.obj)  
tasks_left : 剩余未运行的任务数  


### Task类
#### 成员变量
wf_obj : 任务隶属的工作流(.obj)  
task_id : 任务编号  
functions : 任务包含的所有函数(.obj)  
children : 所有后继(.obj)  
parents : 所有前驱(.obj)  
predecessors_left : 前驱剩余未完成数量  
functions_left : 函数剩余未完成数量  

#### 成员函数
isOK() : 判断任务是否可以开始运行  
isDone() : 判断任务是否已运行完成  


### Function类











## Main函数
全局构造一个边缘服务器列表，每若干秒全局检测边缘服务器的资源状况。

每一个边缘服务器设置一个等待队列，到达的工作流拆解成函数，根据某个特征（诸如最早截止期优先+函数类型）进行排序，依次运行，（是否抢占）。

主函数中生成两个list，分别表示cpu和mem的资源情况，通过下标直接访问某服务器的资源。

对于每个边缘服务器的等待队列，



## 一些待理清的疑问
1、边缘服务器按照什么顺序执行任务  
2、



## 一些假设
1、假设云服距离其他边服距离为10  
2、暂时先拿30个边服出来  
3、每个边缘服务器的cpu资源假设在\[1,4\](核)、内存资源在\[1024,4096\](MB)随机，云服务器设成10000，初始存储的函数类型在限定的几种内随机  
4、假定工作流必须要从它到达的边缘服务器交付，不能整体迁移至其他服务器  
5、目前工作流类型和截止期都写死（一个类型对应一个固定的截止期）  
6、目前边服按照任务的拓扑顺序运行工作流中的任务  
7、每种函数类型对应的执行时间是相同的，也就是事先已知函数的执行时间




## 算法流程
在每一个时间槽开始时：
1. 遍历所有边缘服务器，间隔时间--，如果间隔时间归零，说明该到达工作流了，若无工作流到达则到2，否则到 1.1
- 1.1 边缘服务器接收工作流  
首先该服务器的**间隔时间需要重置**  
接收工作流函数，需要**工作流编号（唯一）、服务器编号、到达时间**参数，服务器随机生成某一类型的工作流，并将该工作流加入到服务器的工作流队列中，同时，将工作流的任务按照拓扑排序解构，并进一步拆分成函数，将{任务(类对象)，函数类型}放入服务器等待队列（FCFS）

2. 在这个时间槽内，遍历边缘服务器的等待队列，对等待队列中的每一个函数进行调度。函数可以通过开始时间和执行时间算出预计完成时间。**每个时间槽内都需要判定**
任务






### 调度器
接收单位为任务，在调度器中获取任务初始所属的服务器、包含函数等信息，对于每一个函数：
1. 函数类型在本地有缓存+本地资源有余 = **在本地直接运行（策略1）** 
2. 函数类型在本地有缓存，但资源不够 = 
- 2.1 等待本地其他运行完毕**在本地直接运行，但是等待其他完成释放资源（策略1plus）加等待时间**
- 2.2 卸载到其他边缘服务器**到其他服务器（策略3）加通信时间** 最短路径（？）
- 2.3 卸载到云服务器（只有在2.1、2.2找不到最佳策略时）**策略4 加通信时间**  冷启动？

3. 函数类型在本地无缓存 = 
- 3.1 本地置换函数类型（需谨慎）**还在本地，但是要换掉类型（策略2）置换类型的等待时间+内存的变化** 决定是否要换 / 换掉哪一个 
- 3.2 卸载到其他边缘服务器**到其他服务器（策略3）**
- 3.3 卸载到云服务器（只有在3.1、3.2找不到最佳策略时）**策略4**

调度器要做的事：1. 给函数的finish_time加上函数的执行时间  2. 决定每个函数去哪里执行


一个一个传会不会太慢了




## 下一步工作
工作流类中存放的任务改为任务类对象 **（这一块后期需要优化）**  
需要在处理数据集时就让工作流存的任务是按照拓扑排序好的

1.10  
qtc 服务器数据集  
任务的前驱列表里可以不存放对象，但后继列表里得放对象，前驱执行完毕后需要通知到后继节点  

服务器等待队列是不是还是应该放任务？以任务为单位进行调度，具体每个函数应该放在哪边执行是调度器应该考虑的事情。等待队列里放的是到达这个服务器的工作里任务中，随时可以运行的部分。每个时间槽遍历时都需要遍历这部分任务。任务一旦交给调度器处理，就要把它从等待队列移除。除此之外服务器应设置一个运行队列，这个队列用来放入正在该服务器上运行的函数。  

1.12  
考虑冷启动  

1.13  
工作流到达服务器后（**这一块优化点：每次在0-1之间随机，超过某个概率就到达工作流，这样可以不每次都计算时间了**），服务器设置工作流队列，每个工作流的任务队列中都是按照拓扑顺序放好的任务，因此每次运行前遍历每个工作流的任务队列时，可以从前到后遍历每个任务.isOK()函数，直到第一个不能开始运行的任务为止。把这些可以立即运行的交给调度器scheduler运行，并把它们从工作流的任务队列中移除。调度器在对任务进行调度的时候，先读到它的函数列表，分别对这些函数进行调度。任务被调度后，需要更改任务开始执行的时间。函数按照卸载策略，被调度到哪个服务器，会有相应的运行时间+(可能的通信时间)，再加上当前时刻，就可以得到该函数的完成时间**所以函数还需要加一个预计完成时间的成员变量，这样任务也需要加一个预计完成时间的成员变量，是所有函数完成时间的最大值，这样工作流还得有一个正在执行的任务列表，每次都需要遍历在当前时刻该任务是否已经执行完毕，执行完毕就要通知到任务的后继节点，这样下一次遍历工作流任务列表的时候就可以让更多任务被调度器执行。**因此，每一个时间槽内：1. 遍历每一个服务器，判断是否需要到达工作流  2. 遍历每一个服务器的每一个工作流的 2.1 正在执行的任务列表，看是否有执行完毕的任务，有的话需要通知它们的后继 2.2 任务列表，看是否有可以扔到调度器里的 2.3 任务列表是否为空，为空则代表这个工作流整体执行完毕，可以根据结束时间和截止期等，算出用户满意度 3. 调度器调度函数时，将函数放入相应服务器的执行队列中，这时函数需要加上一个传输时间（**可能需要根据执行时间排序**），并改变相应服务器的资源 4. 遍历每一个服务器的正在执行队列，查看是否有函数会在这个时间槽内结束，结束的将其弹出执行队列，并释放相应资源。如果不属于这一个服务器的工作流，就要传送回原服务器，会有一个返程的传输时间。

### 还没写
Workflow类中 计算满意度函数（可能要写入文件）  
schedule逻辑  

Functions类 冷启动，需要和Server类联动  
Functions类 funcReturn函数，可能要加上所属服务器之类  

<!-- 目前 不能在服务器上直接运行的一律转移至其他服务器，或者直接上云，所以暂时就没有在服务器等待的情况 -->

1.16  
计算在本地服务器的等待时间？两点1. 本地其他的什么时候结束，等待时间 2. 快结束的够不够执行  
迁移至其他服务器，1. 选择哪个服务器，路径搜索  2. 计算通信时延    退火

用户满意度计算
ddl内 / 所有 

对比算法，任务把函数执行时间加起来  （数据集）

函数执行时间，正态分布

mcea算法

1.17组会后：1. 找服务器的时候，不要陷入局部最优  2. 要不要在当前服务器，预测  3. 冷启动的话，要不要加一个超时休眠机制

1.19 往返时间的计算
传输时间 + 传播时间 = 数据量/带宽 + 距离/传播速度


1.21 
1. 当前假设本地没法直接运行就全部放到其他服务器，即暂时还没考虑在服务器上的等待时间，也就是资源够就直接执行，要么就直接不执行，但考虑了冷启动时间 **不合理，后面要需要加判断条件**
2. 服务器的选择问题
如果服务器之间两两相连，则寻找有某资源的最短路径，考虑**负载均衡**，可以设置距离、备选服务器当前资源情况的权重，主要在于后者，如何定义较为合适  
如果不设置为两两相连，则定义，超过多少距离就视为不连通，这样就可以用到最短路径算法
3. 假设数据每0.5km传播时间需要1s




wf.csv使用到的字段  
wf_type : 可以用编号代替
deadline :
tasks : 任务 "task1, task2, ..."


tasks.csv  
wf_type, task_id, predecessor, successor, func_types

functions.csv


### 2.21 梳理算法逻辑
每一个时刻：对每一台服务器：  
1. 模拟工作流到达（随机值与到达率判断）  
生成工作流，随机一种工作流类型，加入到服务器的工作流队列中  
工作流  
2. 遍历执行队列（执行单位是函数）  
函数执行完毕的话，加上可能的传输时间，更新服务器关于该镜像的最后使用时间  
3. 遍历接收的工作流队列  
3.1 遍历正在被执行的任务队列：  
如果任务执行完成，就通知到它的后继，并弹出正在被执行任务队列  
3.2 遍历尚未被执行队列：  
如果可以开始执行，则加入到工作流的正在被执行队列，并调用调度函数  
3.3 如果工作流可以交付：  
计算满意度，弹出服务器的工作流队列
